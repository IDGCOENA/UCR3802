{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Azure_Blob_DataIngest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_2dLtgGGZ9j"
      },
      "outputs": [],
      "source": [
        "!pip install azure-storage-blob --upgrade\n",
        "!pip install hana_ml\n",
        "!pip install replace"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import replace\n",
        "from azure.storage.blob import BlobServiceClient\n",
        "import pandas as pd\n",
        "import hana_ml.dataframe as dataframe\n",
        "STORAGEACCOUNTURL= 'https://XXXXXX.blob.core.windows.net'  #Replace XXXXXX with your Azure Storage Account\n",
        "STORAGEACCOUNTKEY= '<Insert your Storage Account Access Key>' # Insert your access keys for your Storage Account\n",
        "LOCALFILENAME= 'Jancsv'  #This could be anyname . Just for local download\n",
        "CONTAINERNAME= 'xxxx'   #Insert your container name \n",
        "t1=time.time()\n",
        "blob_service_client_instance = BlobServiceClient(account_url=STORAGEACCOUNTURL, credential=STORAGEACCOUNTKEY)\n",
        "#Provide you connection details below either to ingest data into DWC Container or to HANA Cloud \n",
        "conn = dataframe.ConnectionContext(address = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX', #Provide your OpenSQL Host here\n",
        "                                   port = 443, \n",
        "                                   user = 'XXXXXX', #Provide your OpenSQL container Username here \n",
        "                                   password = 'XXXXXXX', #Provide your OpenSQL contianer password here\n",
        "                                   encrypt = 'true'\n",
        "                                  )\n",
        "container = blob_service_client_instance.get_container_client(CONTAINERNAME)\n",
        "blob_list = container.list_blobs()\n",
        "print(blob_list)\n",
        "for blob in blob_list:\n",
        "  blob_client_instance = blob_service_client_instance.get_blob_client(CONTAINERNAME, blob.name, snapshot=None)\n",
        "  with open(blob.name, \"wb\") as my_blob:\n",
        "      blob_data = blob_client_instance.download_blob()\n",
        "      blob_data.readinto(my_blob)\n",
        "      t2=time.time()\n",
        "print((\"It takes %s seconds to download \"+blob.name) % (t2 - t1))\n",
        "\n",
        "  # LOCALFILE is the file path\n",
        "\n",
        "  dataframe_blobdata = pd.read_csv(blob.name)\n",
        "\n",
        "  key = blob.name\n",
        "  keystr = key.replace(\".csv\",\"\")\n",
        "\n",
        "  print(dataframe_blobdata)\n",
        "#Insert into DWC Open SQL container \n",
        "  df_remote = dataframe.create_dataframe_from_pandas(connection_context = conn, \n",
        "                                                   pandas_df = dataframe_blobdata, \n",
        "                                                   table_name = keystr,\n",
        "                                                   #schema = 'XXXX',   #Schema name is not needed for DWC Open SQL Container \n",
        "                                                   force = True,\n",
        "                                                   replace = True)\n",
        "\n"
      ],
      "metadata": {
        "id": "VgwADozGGcU1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}